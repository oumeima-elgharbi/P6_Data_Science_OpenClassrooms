{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "- OpenClassrooms Project 6, Data Scientist\n",
    "- Author : Oumeima EL GHARBI\n",
    "- Date : October, November 2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    },
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
    "\n",
    "import pandas as pd\n",
    "# to compute time of pipeline\n",
    "from time import time, strftime, gmtime\n",
    "\n",
    "from common_graphs import *\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from bag_of_words import *\n",
    "from Word2Vec import *\n",
    "from BERT import *\n",
    "from transformers import TFAutoModel\n",
    "from USE import *\n",
    "\n",
    "%matplotlib inline\n",
    "%autosave 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "Num GPUs Available:  0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TF_KERAS\"]='1'\n",
    "\n",
    "print(tf.__version__)\n",
    "#print(tensorflow.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Starting time\n",
    "t0 = time()\n",
    "\n",
    "input_path = \"./dataset/cleaned/\"\n",
    "input_filename = \"final_data_text.csv\"\n",
    "input_file = \"{}{}\".format(input_path, input_filename)\n",
    "\n",
    "output_path = \"./dataset/cleaned/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        product_name  \\\n0  Elegance Polyester Multicolor Abstract Eyelet ...   \n1                         Sathiyas Cotton Bath Towel   \n2                Eurospa Cotton Terry Face Towel Set   \n3  SANTOSH ROYAL FASHION Cotton Printed King size...   \n4  Jaipur Print Cotton Floral King sized Double B...   \n\n                                                text          category  \\\n0  Key Features of Elegance Polyester Multicolor ...  Home Furnishing    \n1  Specifications of Sathiyas Cotton Bath Towel (...        Baby Care    \n2  Key Features of Eurospa Cotton Terry Face Towe...        Baby Care    \n3  Key Features of SANTOSH ROYAL FASHION Cotton P...  Home Furnishing    \n4  Key Features of Jaipur Print Cotton Floral Kin...  Home Furnishing    \n\n   target                                         clean_text  \\\n0       4  key featur eleg polyest multicolor abstract ey...   \n1       0  specif bath towel bath towel red yellow blue b...   \n2       0  key featur terri face towel set size small hei...   \n3       4  key featur royal fashion print king size doubl...   \n4       4  key featur print floral king size doubl print ...   \n\n                             clean_product_name  _len_clean_text_  \\\n0  eleg polyest multicolor abstract eyelet door               136   \n1                             cotton bath towel                49   \n2                   cotton terri face towel set               118   \n3    royal fashion cotton print king size doubl                89   \n4           print cotton floral king size doubl               118   \n\n   _len_clean_product_name_  \\\n0                         6   \n1                         3   \n2                         5   \n3                         7   \n4                         6   \n\n                                   text_bag-of-words  \\\n0  key features elegance polyester multicolor abs...   \n1  specifications sathiyas cotton bath towel bath...   \n2  key features eurospa cotton terry face towel s...   \n3  key features santosh royal fashion cotton prin...   \n4  key features jaipur print cotton floral king s...   \n\n                               text_bag-of-words_lem  \\\n0  key feature elegance polyester multicolor abst...   \n1  specification sathiyas cotton bath towel bath ...   \n2  key feature eurospa cotton terry face towel se...   \n3  key feature santosh royal fashion cotton print...   \n4  key feature jaipur print cotton floral king si...   \n\n                                   text_deeplearning  length_bag-of-words  \\\n0  key features of elegance polyester multicolor ...                  156   \n1  specifications of sathiyas cotton bath towel (...                   63   \n2  key features of eurospa cotton terry face towe...                  158   \n3  key features of santosh royal fashion cotton p...                  114   \n4  key features of jaipur print cotton floral kin...                  156   \n\n   length_deeplearning  \n0                  248  \n1                   84  \n2                  252  \n3                  148  \n4                  228  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_name</th>\n      <th>text</th>\n      <th>category</th>\n      <th>target</th>\n      <th>clean_text</th>\n      <th>clean_product_name</th>\n      <th>_len_clean_text_</th>\n      <th>_len_clean_product_name_</th>\n      <th>text_bag-of-words</th>\n      <th>text_bag-of-words_lem</th>\n      <th>text_deeplearning</th>\n      <th>length_bag-of-words</th>\n      <th>length_deeplearning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Elegance Polyester Multicolor Abstract Eyelet ...</td>\n      <td>Key Features of Elegance Polyester Multicolor ...</td>\n      <td>Home Furnishing</td>\n      <td>4</td>\n      <td>key featur eleg polyest multicolor abstract ey...</td>\n      <td>eleg polyest multicolor abstract eyelet door</td>\n      <td>136</td>\n      <td>6</td>\n      <td>key features elegance polyester multicolor abs...</td>\n      <td>key feature elegance polyester multicolor abst...</td>\n      <td>key features of elegance polyester multicolor ...</td>\n      <td>156</td>\n      <td>248</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sathiyas Cotton Bath Towel</td>\n      <td>Specifications of Sathiyas Cotton Bath Towel (...</td>\n      <td>Baby Care</td>\n      <td>0</td>\n      <td>specif bath towel bath towel red yellow blue b...</td>\n      <td>cotton bath towel</td>\n      <td>49</td>\n      <td>3</td>\n      <td>specifications sathiyas cotton bath towel bath...</td>\n      <td>specification sathiyas cotton bath towel bath ...</td>\n      <td>specifications of sathiyas cotton bath towel (...</td>\n      <td>63</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Eurospa Cotton Terry Face Towel Set</td>\n      <td>Key Features of Eurospa Cotton Terry Face Towe...</td>\n      <td>Baby Care</td>\n      <td>0</td>\n      <td>key featur terri face towel set size small hei...</td>\n      <td>cotton terri face towel set</td>\n      <td>118</td>\n      <td>5</td>\n      <td>key features eurospa cotton terry face towel s...</td>\n      <td>key feature eurospa cotton terry face towel se...</td>\n      <td>key features of eurospa cotton terry face towe...</td>\n      <td>158</td>\n      <td>252</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SANTOSH ROYAL FASHION Cotton Printed King size...</td>\n      <td>Key Features of SANTOSH ROYAL FASHION Cotton P...</td>\n      <td>Home Furnishing</td>\n      <td>4</td>\n      <td>key featur royal fashion print king size doubl...</td>\n      <td>royal fashion cotton print king size doubl</td>\n      <td>89</td>\n      <td>7</td>\n      <td>key features santosh royal fashion cotton prin...</td>\n      <td>key feature santosh royal fashion cotton print...</td>\n      <td>key features of santosh royal fashion cotton p...</td>\n      <td>114</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jaipur Print Cotton Floral King sized Double B...</td>\n      <td>Key Features of Jaipur Print Cotton Floral Kin...</td>\n      <td>Home Furnishing</td>\n      <td>4</td>\n      <td>key featur print floral king size doubl print ...</td>\n      <td>print cotton floral king size doubl</td>\n      <td>118</td>\n      <td>6</td>\n      <td>key features jaipur print cotton floral king s...</td>\n      <td>key feature jaipur print cotton floral king si...</td>\n      <td>key features of jaipur print cotton floral kin...</td>\n      <td>156</td>\n      <td>228</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baby Care ', 'Watches ', 'Kitchen & Dining ', 'Home Decor & Festive Needs ', 'Beauty and Personal Care ', 'Home Furnishing ', 'Computers ']\n",
      "catégories :  ['Baby Care ', 'Watches ', 'Kitchen & Dining ', 'Home Decor & Festive Needs ', 'Beauty and Personal Care ', 'Home Furnishing ', 'Computers ']\n"
     ]
    },
    {
     "data": {
      "text/plain": "0       4\n1       0\n2       0\n3       4\n4       4\n       ..\n1045    0\n1046    0\n1047    0\n1048    0\n1049    0\nName: target, Length: 1050, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_cat = list(set(data['category']))\n",
    "print(l_cat)\n",
    "\n",
    "print(\"catégories : \", l_cat)\n",
    "y_cat_num = data[\"target\"]\n",
    "y_cat_num"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Bag of Words : Count words + TF-IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) fit / transform description - text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1) Preparing the vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "feat = ['text'] # 'text' 0.399 et 0.5567 / text_bag-of-words_lem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vector\n",
      "TF-IDF\n"
     ]
    }
   ],
   "source": [
    "cv_transform, ctf_transform = create_bag_of_words_vectors(data, feat, feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 5843)\n",
      "(1050, 5843)\n"
     ]
    }
   ],
   "source": [
    "print(cv_transform.shape)\n",
    "print(ctf_transform.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2) Executing the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer : \n",
      "-----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15736/742458157.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"CountVectorizer : \"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"-----------------\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mARI\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_tsne\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mARI_fct\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcv_transform\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ml_cat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_cat_num\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Tf-idf : \"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\OC_projets\\P6\\P6_Data_Science_OpenClassrooms\\common_graphs.py\u001B[0m in \u001B[0;36mARI_fct\u001B[1;34m(features, l_cat, y_cat_num)\u001B[0m\n\u001B[0;32m     31\u001B[0m     tsne = TSNE(n_components=2, perplexity=30, n_iter=2000,\n\u001B[0;32m     32\u001B[0m                 init='random', learning_rate=200, random_state=seed)\n\u001B[1;32m---> 33\u001B[1;33m     \u001B[0mX_tsne\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtsne\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[1;31m# Détermination des clusters à partir des données après Tsne\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\manifold\\_t_sne.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m   1121\u001B[0m         \"\"\"\n\u001B[0;32m   1122\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_params_vs_input\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1123\u001B[1;33m         \u001B[0membedding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1124\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0membedding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1125\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\manifold\\_t_sne.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, skip_num_points)\u001B[0m\n\u001B[0;32m   1016\u001B[0m         \u001B[0mdegrees_of_freedom\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_components\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1017\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1018\u001B[1;33m         return self._tsne(\n\u001B[0m\u001B[0;32m   1019\u001B[0m             \u001B[0mP\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1020\u001B[0m             \u001B[0mdegrees_of_freedom\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\manifold\\_t_sne.py\u001B[0m in \u001B[0;36m_tsne\u001B[1;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001B[0m\n\u001B[0;32m   1084\u001B[0m             \u001B[0mopt_args\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"momentum\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0.8\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1085\u001B[0m             \u001B[0mopt_args\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"n_iter_without_progress\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_iter_without_progress\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1086\u001B[1;33m             \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkl_divergence\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_gradient_descent\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj_func\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mopt_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1087\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1088\u001B[0m         \u001B[1;31m# Save the final number of iterations\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\manifold\\_t_sne.py\u001B[0m in \u001B[0;36m_gradient_descent\u001B[1;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001B[0m\n\u001B[0;32m    396\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"compute_error\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_convergence\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mn_iter\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 398\u001B[1;33m         \u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobjective\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    399\u001B[0m         \u001B[0mgrad_norm\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    400\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\manifold\\_t_sne.py\u001B[0m in \u001B[0;36m_kl_divergence_bh\u001B[1;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    278\u001B[0m     \u001B[0mgrad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_embedded\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 279\u001B[1;33m     error = _barnes_hut_tsne.gradient(\n\u001B[0m\u001B[0;32m    280\u001B[0m         \u001B[0mval_P\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    281\u001B[0m         \u001B[0mX_embedded\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"CountVectorizer : \")\n",
    "print(\"-----------------\")\n",
    "ARI, X_tsne, labels = ARI_fct(cv_transform, l_cat, y_cat_num)\n",
    "print()\n",
    "print(\"Tf-idf : \")\n",
    "print(\"--------\")\n",
    "ARI, X_tsne, labels = ARI_fct(ctf_transform, l_cat, y_cat_num)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3) Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) fit / transform product_name + text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1) Preparing the vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# création du bag of words (CountVectorizer et Tf-idf)\n",
    "print(\"Separate vocabulary\")\n",
    "\n",
    "textual_columns = ['product_name', 'text']\n",
    "\n",
    "cv_transform, ctf_transform = create_bag_of_words_vectors(data, textual_columns, textual_columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cv_transform.shape)\n",
    "print(ctf_transform.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2) Executing the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"CountVectorizer : \")\n",
    "print(\"-----------------\")\n",
    "ARI, X_tsne, labels = ARI_fct(cv_transform, l_cat, y_cat_num)\n",
    "print()\n",
    "print(\"Tf-idf : \")\n",
    "print(\"--------\")\n",
    "ARI, X_tsne, labels = ARI_fct(ctf_transform, l_cat, y_cat_num)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3) Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3) fit product_name / transform text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1) Preparing the vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# création du bag of words (CountVectorizer et Tf-idf)\n",
    "\n",
    "feat_fit = ['product_name']\n",
    "feat_transform = ['text_bag-of-words_lem'] # text / text_bag-of-words_lem\n",
    "\n",
    "cv_transform, ctf_transform = create_bag_of_words_vectors(data, feat_fit, feat_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cv_transform.shape)\n",
    "print(ctf_transform.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2) Executing the models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"CountVectorizer : \")\n",
    "print(\"-----------------\")\n",
    "ARI, X_tsne, labels = ARI_fct(cv_transform, l_cat, y_cat_num)\n",
    "print()\n",
    "print(\"Tf-idf : \")\n",
    "print(\"--------\")\n",
    "ARI, X_tsne, labels = ARI_fct(ctf_transform, l_cat, y_cat_num)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3) Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Conclusion bag of words\n",
    "We have tried counting the occurrences of each sentence according to the vocabulary and we have also tried tf-idf.\n",
    "We got the best results while using \"product_name\".\n",
    "\n",
    "We got better results with the raw sentences than with the cleaned ones.\n",
    "\n",
    "The best ARI = 0.56 with fit/transform product_name or fit/transform text."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### II) Words Embeddings : Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1) Creating a Word2Vec model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_size=300\n",
    "w2v_window=5\n",
    "w2v_min_count=1\n",
    "w2v_epochs=100\n",
    "maxlen = 24 # adapt to length of sentences\n",
    "sentences = data['product_name'].to_list() # text : 0.19 ARI / text_bag-of-words_lem : 0.21\n",
    "sentences = [gensim.utils.simple_preprocess(text) for text in sentences]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_words, model_vectors = create_w2v_model(sentences, w2v_min_count, w2v_size, w2v_window, w2v_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2) Preparing the sentences (tokenization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_sentences, tokenizer = tokenize_sentences(sentences, maxlen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3) Creating the embedding matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_matrix, vocab_size = create_embedding_matrix(w2v_words, model_vectors, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4) Creating the embedded model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embed_model = create_embedding_model(x_sentences, maxlen, vocab_size, w2v_size, embedding_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 5) Execution of the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embeddings = embed_model.predict(x_sentences)\n",
    "embeddings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ARI, X_tsne, labels = ARI_fct(embeddings, l_cat, y_cat_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Conclusion Word2Vec\n",
    "We get good results with Word2Vec word embedding.\n",
    "\n",
    "We got better results with the raw sentences than with the cleaned ones.\n",
    "\n",
    "The best ARI = 0.5 with product_name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III) Words Embeddings : BERT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) BERT HuggingFace"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1.1) 'bert-base-uncased'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "batch_size = 10\n",
    "model_type = 'bert-base-uncased'\n",
    "model = TFAutoModel.from_pretrained(model_type)\n",
    "sentences = data['product_name'].to_list() # clean_text 0.29"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Création des features\n",
    "\n",
    "features_bert, last_hidden_states_tot = feature_BERT_fct(model, model_type, sentences,\n",
    "                                                         max_length, batch_size, mode='HF')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ARI, X_tsne, labels = ARI_fct(features_bert, l_cat, y_cat_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "##### 1.2) Trying another pre trained NLP model\n",
    "* Pre-trained model based on classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "sentences = data['product_name'].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "max_length = 64\n",
    "batch_size = 10\n",
    "model_type = \"sampathkethineedi/industry-classification\"\n",
    "\n",
    "#\"Kk2k/distilbert_e-commerce_data\"\n",
    "#'MyOrg123/all-intent-classification'\n",
    "# \"Kk2k/distilbert_e-commerce_data\"\n",
    "# \"sampathkethineedi/industry-classification\"\n",
    "# \"LiYuan/amazon-query-product-ranking\"\n",
    "\n",
    "model = TFAutoModel.from_pretrained(model_type, from_pt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "features_bert, last_hidden_states_tot = feature_BERT_fct(model, model_type, sentences,\n",
    "                                                         max_length, batch_size, mode='HF')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 987ms/step\n"
     ]
    }
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "ARI, X_tsne, labels = ARI_fct(features_bert, l_cat, y_cat_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) BERT hub Tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Guide about Tensorflow hub : https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "model_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "bert_layer = hub.KerasLayer(model_url, trainable=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentences = data['product_name'].to_list() # text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "batch_size = 10\n",
    "model_type = 'bert-base-uncased'\n",
    "model = bert_layer\n",
    "\n",
    "features_bert, last_hidden_states_tot = feature_BERT_fct(model, model_type, sentences,\n",
    "                                                         max_length, batch_size, mode='TFhub')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ARI, X_tsne, labels = ARI_fct(features_bert, l_cat, y_cat_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Conclusion BERT\n",
    "\n",
    "We get good results with BERT word embedding.\n",
    "\n",
    "We got better results with the raw sentences than with the cleaned ones.\n",
    "\n",
    "The best ARI = 0.62 with product_name for the pre-trained model : ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV) Words Embeddings : USE (Universal Sentence Encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://tfhub.dev/google/universal-sentence-encoder/4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using product_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "sentences = data['product_name'].to_list() # no preprocessing better !! ? to check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_USE = feature_USE_fct(embed, sentences, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ARI, X_tsne, labels = ARI_fct(features_USE, l_cat, y_cat_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using text / clean_text : cleaned or not"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "sentences = data['text_deeplearning'].to_list() # no preprocessing better !! ? to check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_USE = feature_USE_fct(embed, sentences, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ARI, X_tsne, labels = ARI_fct(features_USE, l_cat, y_cat_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, l_cat, labels, ARI)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Conclusion USE\n",
    "We get good results with USE word embedding.\n",
    "\n",
    "We got better results with the raw sentences than with the cleaned ones.\n",
    "\n",
    "The best ARI = ... with product_name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "* It seems like the classification of products based on NLP might be doable.\n",
    "* Using KMeans clustering, we categorized the products using bag of words and word embeddings.\n",
    "* Best ARI :"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# End of notebook time\n",
    "t1 = time()\n",
    "print(\"computing time : {:8.6f} sec\".format(t1 - t0))\n",
    "print(\"computing time : \" + strftime('%H:%M:%S', gmtime(t1 - t0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}