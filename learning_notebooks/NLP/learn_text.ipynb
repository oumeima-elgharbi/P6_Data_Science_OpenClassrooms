{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## I) Pré traitement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0) Récupération"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db = load_all_sentences();\n",
    "print('chargement de {} vers dans la db'.format(len(db.keys())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "base_artistes = defaultdict(set)\n",
    "for k,v in db.iteritems():\n",
    "    base_artistes[v['artistes']].add(k)\n",
    "artistes = { k:v for k,v in artistes.iteritems() if len(v) > 200 }\n",
    "print('{} artistes'.format(len(artistes)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "test = \"Bonjour, je suis un texte d'exemple pour le cours d'Openclassrooms. Soyez attentifs à ce cours !\"\n",
    "\n",
    "nltk.word_tokenize(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(\"Bonjour, je suis un texte d'exemple pour le cours d'Openclassrooms. Soyez attentifs à ce cours !\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def freq_stats_corpora():\n",
    "    corpora = defaultdict(list)\n",
    "\n",
    "    # Création d'un corpus de tokens par artiste\n",
    "    for artiste,sentence_id in artistes.iteritems():\n",
    "        for sentence_id in sentence_id:\n",
    "            corpora[artiste] += tokenizer.tokenize(\n",
    "                db[sentence_id]['text'].decode('utf-8').lower()\n",
    "            )\n",
    "\n",
    "    stats, freq = dict(), dict()\n",
    "\n",
    "    for k, v in corpora.iteritems():\n",
    "        freq[k] = fq = nltk.FreqDist(v)\n",
    "        stats[k] = {'total': len(v)}\n",
    "\n",
    "    return (freq, stats, corpora)\n",
    "\n",
    "# Récupération des comptages\n",
    "freq, stats, corpora = freq_stats_corpora()\n",
    "df = pd.DataFrame.from_dict(stats, orient='index')\n",
    "\n",
    "# Affichage des fréquences\n",
    "df.sort(columns='total', ascending=False)\n",
    "df.plot(kind='bar', color=\"#f56900\", title='Top 50 Rappeurs par nombre de mots')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def freq_stats_corpora():\n",
    "    corpora = defaultdict(list)\n",
    "    for artiste,sentence_ids in artistes.iteritems():\n",
    "        for sentence_id in sentence_ids:\n",
    "            corpora[artiste] += tokenizer.tokenize(\n",
    "                db[sentence_id]['text'].decode('utf-8').lower()\n",
    "            )\n",
    "\n",
    "    stats, freq = dict(), dict()\n",
    "\n",
    "    for k, v in corpora.iteritems():\n",
    "        freq[k] = fq = nltk.FreqDist(v)\n",
    "        stats[k] = {'total': len(v), 'unique': len(fq.keys())}\n",
    "\n",
    "    return (freq, stats, corpora)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Nettoyage / Normalisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) supprimer les stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Premièrement, on récupère la fréquence totale de chaque mot sur tout le corpus d'artistes\n",
    "freq_totale = nltk.Counter()\n",
    "for k, v in corpora.iteritems():\n",
    "    freq_totale += freq[k]\n",
    "\n",
    "# Deuxièmement on décide manière un peu arbitraire du nombre de mots les plus fréquents à supprimer. On pourrait afficher un graphe d'évolution du nombre de mots pour se rendre compte et avoir une meilleure heuristique.\n",
    "most_freq = zip(*freq2.most_common(100))[0] # stopwords =\n",
    "\n",
    "# On créé notre set de stopwords final qui cumule ainsi les 100 mots les plus fréquents du corpus ainsi que l'ensemble de stopwords par défaut présent dans la librairie NLTK\n",
    "sw = set()\n",
    "sw.update(stopwords)\n",
    "sw.update(tuple(nltk.corpus.stopwords.words('french')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def freq_stats_corpora2(lookup_table=[]):\n",
    "    corpora = defaultdict(list)\n",
    "    for artist, block_ids in lt_artists.iteritems():\n",
    "        for block_id in block_ids:\n",
    "            tokens = tokenizer.tokenize(db_flat[block_id]['text'].decode('utf-8'))\n",
    "            corpora[artist] += [w for w in tokens if not w in list(sw)]\n",
    "\n",
    "    stats, freq = dict(), dict()\n",
    "\n",
    "    for k, v in corpora.iteritems():\n",
    "        freq[k] = fq = nltk.FreqDist(v)\n",
    "        stats[k] = {'total': len(v), 'unique': len(fq.keys())}\n",
    "    return (freq, stats, corpora)\n",
    "\n",
    "freq2, stats2, corpora2 = freq_stats_corpora2()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Lemmatisation ou racinisation (stemming)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Racinisation :"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "def freq_stats_corpora3(lookup_table=[]):\n",
    "    corpora = defaultdict(list)\n",
    "    for artist, block_ids in lt_artists.iteritems():\n",
    "        for block_id in block_ids:\n",
    "            tokens = tokenizer.tokenize(db_flat[block_id]['text'].decode('utf-8').lower())\n",
    "            corpora[artist] += [stemmer.stem(w) for w in tokens if not w in list(sw)]\n",
    "\n",
    "    stats, freq = dict(), dict()\n",
    "\n",
    "    for k, v in corpora.iteritems():\n",
    "        freq[k] = fq = nltk.FreqDist(v)\n",
    "        stats[k] = {'total': len(v), 'unique': len(fq.keys())}\n",
    "    return (freq, stats, corpora)\n",
    "\n",
    "freq3, stats3, corpora3 = freq_stats_corpora3()\n",
    "df3 = pd.DataFrame.from_dict(stats3, orient='index').sort(columns='unique', ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1) Exploratory Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quelle est la forme du Dataframe ?\n",
    "\n",
    "Y a t-il des valeurs manquantes ou des valeurs dupliquées ?\n",
    "\n",
    "Quelles sont les colonnes qui vont nous intéresser ?\n",
    "\n",
    "Y a-t-il des données aberrantes ou des incohérences majeures dans les données ?\n",
    "\n",
    "Y a t-il des tweets anormalement longs / courts ? Peut-on les considérer comme des outliers ?\n",
    "\n",
    "Quel est le ratio tweet qui parlent de “catastrophes” / tweet normaux ?\n",
    "\n",
    "En regardant quelques tweets au hasard, peut-on deviner facilement la “target” ?\n",
    "\n",
    "Peut-on déjà détecter des “patterns” ou des mots clés dans les tweets?\n",
    "\n",
    "A votre avis quel serait l’accuracy score qu’un humain pourrait obtenir s’il prédisait  les données “à la main” ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2) Text Processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pouvez-vous écrire une fonction qui : tokenize un document, supprime les stopwords, supprime les tokens de moins de 3 lettres ?\n",
    "\n",
    "Comment peut-on reconstituer le corpus (c'est-à dire un texte avec l’ensemble des documents) ?\n",
    "\n",
    "Une fois ce corpus constitué, combien de tokens uniques le constitue? Ce nombre vous apparaît-il faible, important, gigantesque ?\n",
    "\n",
    "Comment réduire ce nombre de tokens uniques, ou autrement dit “comment réduire la taille du vocabulaire” de ce corpus ?\n",
    "\n",
    "Combien de tokens sont présents une seule fois ? Ces tokens nous seront-ils utiles ?\n",
    "\n",
    "Appliquer une méthode de stemmatisation ou de lemmatisation peut-elle nous aider à réduire la dimensionnalité du corpus ?\n",
    "\n",
    "Comment visualiser graphiquement, par un WordCloud par exemple, les tokens les plus présents ?\n",
    "\n",
    "Pouvez vous appliquer tous les traitements évoqués afin de créer une nouvelle colonne “text” qui serait plus pertinente ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# II) ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}